 Halo semua dan selamat datang di kursus Neural Convolutional, dengan pembelajaran python bagian 9. Neural Convolutional adalah salah satu kursus yang menarik dan membuktikan bahwa siswa yang mengikuti kursus ini akan lebih cepat dan mudah mengerti. Saya akan memberikan pembelajaran tentang pendalaman materi yang dapat membantu anda dalam pembelajaran  dengan banyaknya materi- materi.
Jadi, izinkan saya menjelaskan dengan secara  singkat tentang kursus ini	:

 Dalam kursus ini kita akan mempelajari bagaimana cara mengatur antara arsitektur CNN dasar yang sudah anda kenal dan menikmati arsitektur novel modern seperti Viji Reznick dan Inception yang mungkin akan anda beri sesuai nama film. Kami akan menggunakan ini pada gambar sel sel dan membuat sistem yang lebih baik.
 Salah satu tema utama dari kursus ini juga beralih dari CNN ke sistem yang melibatkan CNN. CNN juga membuat satu gambar klasifikasi hal dasar dalam kursus ini, anda akan melihat bagaimana kita dapat mengubah CNN menjadi sistem deteksi objek yang tidak hanya mengklasifikasikan gambar tetapi juga dapat menemukan setiap objek dalam gambar dan prediksi labelnya.



\section{Jaringan saraf convolutional canggih}
Tujuan Pembelajaran
\begin{enumerate}

\item  kita telah melihat bahwa 3-5 layer netscan membutuhkan waktu yang sangat lama untuk dilatih
(tapi sekarang kita akan melihat 50 layer nets)
\item penelitian hari ini (dalam pembelajaran mesin) berkomitmen untuk keterbukaan, dan dengan membagikan penelitian mereka, mudah bagi Anda untuk melakukan hal-hal canggih di rumah
(Tidak ada bidang lain yang bisa mencapai ini: biologi, kedokteran, fisika, ...dan lain sebagainya)
\item kita dapat menggunakan bobot pra-terlatih menggunakan transfer belajar secara signifikan mengurangi waktu pelatihan karena kita sekarang hanya perlu melakukan fine-tuning
\end{enumerate}

\section{cara untuk melakukan kursus ini dengan baik}
Saya telah menemukan solusi ini setelah mengamati siswa/i selama bertahun-tahun,
pada umumnya, mereka yang mengikuti solusi ini telah mendapatkan kesuksesan, mereka yang memiliki masalah disebabkan karena tidak mengikuti solusi ini.

Hal-hal atau solusi yang diperlukan antara lain :
\begin{enumerate}
\item memanfaatkan dengan adanya Question and Answer  
\item memerlukan waktu respon yang cepat
\item mempunyai motifasi yang tinggi
\item menggunakan sotfware yang kita mengerti dan kita pahami 
\end {enumerate}


\section{Convolutional Neural Network}
Ulasan tentang CNN
\begin{enumerate}

\item Memahami penulisan jaringan saraf feedforward menggunakan beberapa pustaka
\item Mengetahui secara umum bagaimana jaringan saraf bekerja, bagaimana melatihnya pada data, seperti apa data itu (formatnya), bagaimana membuat prediksi baru tentang data tersebut.
\item Mengetahui tentang convolution
\end{enumerate}

Convolution
\begin{enumerate}
\item Filter(3X3) adalah tensor berat yang dipelajari dengan backpropagation.
\item Kesalahan : merancang filter untuk menjadi pendeteksi tepi dll.
\item Tidak dapat diskalakan: CNN berisi seribuan filter saraf sehingga tidak mungkin anda dapat memperbaiki dengan cara yang dapat dilakukan sesuai kebutuhan anda
\end{enumerate}

\begin{figure}[!htp]
	\includegraphics[width=0.75\textwidth]{figures/convolusi.PNG}
	\caption{Ilustasi gambar pada setiap pergeseran filter}
	\label{labelgambar}
\end{figure}
	Convolutional Neural Network (CNN) adalah salah satu jenis neural network yang biasa digunakan pada data image. CNN bisa digunakan untuk mendeteksi dan mengenali object pada sebuah image.
Secara garis besar CNN tidak jauh beda dengan neural network biasanya. CNN terdiri dari neuron yang memiliki weight, bias dan activation function.
Filter pada dasarnya meluncur diatas setiap posisi yang mungkin pada gambar dan pada setiap bagian yang tumpang tindih mendapatkan elemen berlipat ganda untuk pengadaan dan penambahan konvolusi ini merupakan konsep matrix seperti teknik pengukuran jarak ataupun mengukur korelasi sebuah matrix 
Jika filter sangat berkolerasi dengan potongan gambar maka akan menghasilkan jumlah yang sangat besar dan jika filter sangat berbeda dengan potongan gambar maka akan menghasilkan jumlah yang sangat kecil dalam aktualitas yang disebut konvolusi atau disebut sebagai korelasi silang karena konvolusi merupakan sebuah konsep 


\section{cara untuk mendapatkan kode dan data}
Langkahnya sebagai berikut
\begin{figure}[!htp]
	\includegraphics[width=0.75\textwidth]{figures/ssh.JPG}
	\caption{contoh pengambilan kode ssh}
	\label{labelgambar}
\end{figure}

\begin{enumerate}
\item mengambil kode ssh yang ada pada github dan pastikan yang dicopy adalah ssh bukan https
\item jangan lupa melakukan fork terlebih dahulu
\item kemudian disarankan untuk tidak memalsukan repo karena dapat mempersulit 
\end{enumerate}

Dalam hal data, data akan kita temui pada saat kita dalam kuliah dan kursus, beberapa siswa telah meminta saya untuk memberikan 
tentang tutorial latihan coding dalam kursus ini jadi tidak ada alasan lagi untuk tidak dapat mengoding

\begin{enumerate}
\item Jaringan saraf konvolutional canggih dalam kuliah ini saya akan membahas bagaimana untuk mendapatkan kode untuk kursus ini. Jadi seperti biasa kode dalam kursus ini dapat di unduh dari halaman saya. Untuk mendapatkan kunci tersebut, cobalah untuk mencoba dan menempelkan dari halaman web itu sendiri. Cukup gunakan perintah clone lalu buat semua folder yang relevan untuk kursus ini juga kelas CNN.
\item Tidak memalsukan report karena hal ini mempersulit untuk mendapatkan persetujuan dan saya membuat report yang cukup banyak dan terus menerus sehingga membuat anda tidak terjebak dengan versi lama. Selanjutnya jika anda sudah mengambil salah satu kelas saya dan anda sudah memiliki report ini cukup klik tarik dan anda secara otomatis memiliki kode untuk data dalam kursus ini.
\item Umumnya akan melihat data set yang berbeda, dimana untuk mendapatkan data didua tempat, baik dalam kuliah dan dalam kode. Jadi dalam kursus ini anda tidak perlu mengetik kode berulang kali hanya untuk melihat data set yang berbeda.
\end{enumerate}

\section{Data Fashion MNIST}
Data Fashion MNIST (Modified National Institute of Standards and Technology) adalah basis data yang berbentuk tulisan angka yang biasa digunakan untuk melatih pola pikir kita dalam algoritma.

Hal hal yang perlu kita lakukan untuk kursus Data Fashion MNIST :
\begin{enumerate}
\item Download terlebih dahulu kaggle pada google
\item Sebelum mendownload pastikan kamu telah memiliki akun kaggle 
\item Sediakan tempat penyimpanan file yang besar
\end{enumerate}

Kali ini kita akan melakukan contoh klasifikasi terhadap data Fashion MNIST. Fashion MNIST ini adalah dataset yang terdiri dari 10 kategori fashion sebagai berikut :
\begin{figure}[!htp]
	\includegraphics[width=0.75\textwidth]{figures/MNIST.PNG}
	\caption{contoh klarifikasi data Fashion MNIST}
	\label{labelgambar}
\end{figure}

\textbf{Hasil Klarifikasi}
\begin{enumerate}
\item T-Shirt/Tops = 0
\item Trouser = 1
\item Pullover = 2
\item Dress = 3
\item Coat = 4
\item Sandal = 5
\item Shirt = 6
\item Sneaker = 7
\item Bag = 8
\item Ankle Boot = 9
\end{enumerate}

Tiap kategori terdiri dari 6.000 images untuk training dan 1.000 images untuk testing. Jadi total untuk training data ada 60.000 images dan 10.000 untuk testing data.
 

\subsection{Dependency}
Dependency yang dibutuhkan pada contoh autoencoder kali ini hampir sama dengan contoh pada part-part sebelumnya. Hanya saja kali ini kita akan load MNIST data dari package yang sudah disediakan oleh Keras. Kita juga mau coba optimizers baru yaitu ADAM.

ADAM adalah variant dari algoritma gradient descent.
\begin{figure}[!htp]
	\includegraphics[width=0.75\textwidth]{figures/Dependency.JPG}
	\caption{contoh dependency}
	\label{labelgambar}
\end{figure}

\subsection{Data Preparation}
Data dari MNIST ini adalah grayscale image dengan range dari 0 hingga 255. Range data seperti ini “terlalu besar” untuk model kita, apalagi dengan learning rate yang cukup kecil, sehingga kita perlu melakukan scaling dengan membaginya dengan 255. Sehingga kita dapatkan range data baru antara 0 dan 1.


\section{Pengulasan tentang kode CNN}
Halo kembali lagi di materi jaringan Saraf Convolutional canggih, dalam kesempatan ini kita akan melihat bagaimana sebuah kode dapat digunakan untuk menerapkan CNN dan karies dengan menggunakan metode data amneris. Apa yang akan dipelajari adalah betapa mudahnya kode tersebut dapat membaca dokumentasi Cairnes selama beberapa menit. Jadi strategi dalam membuat data jaringan saraf pada dasarnya hanya mendeklarasikan daftar surat yang ingin dipelajari dengan jaringan yang hanya satu baris dan kemudian plot biaya dan metrik lainya, namun ini semua terlihat mudah karena hanya sebuah penjelasan. Sebelum memulai pembelajaraan ini, kita dapat melihat fashion yang tinggi di repo, seperti yang kita lihat diatas ada beberapa impor seperti jenis model yang kita inginkan secara berurutan dan semua jenis model yang diperlukan. Sebelumnya kami telah mempelajari semua jenis yang ada dimasa lalu sehingga kami dapat menemukan ide dan menggunakan untuk jenis model yang digunakan sekarang. Kami memiliki indikator untuk menentukan target yang berupa daftar indeks sehingga menjadi satu kesatuan yang berfungsi untuk mengategorikan data tersebut. jika pada dasarnya anda bisa menyalin kode apapun dari pembelajaraan sebelumnya yang dimuat dalam data yang sama yang akan dilakukan Karin. Untuk melakukan validasi split kereta. Tetapi disini saya mengacak-acak data untuk berjaga-jaga. Ingatlah bahwa kami ingin data berada dalam bentuk dan ketinggian dengan warna. Jadi kami membentuk ulang menjadi minus satu pada 28 satu. Karena gambar berukuran 28 x 28 dan skala abu-abu, kami juga ingin piksel gambar kami dinormalisasi sehingga kami membagi semuanya dengan 255 dan seperti halnya amnesti asli untuk mengatur label pada kolom pertama. Jadi X adalah segalanya mulai dari kolom 1 dan seterusnya. Dan mengapa semuanya ada di kolom 0. Selanjutnya kita mendapatkan K yang merupakan jumlah kelas dan pada baris berikutnya kita mengubah y menjadi matriks indikator sehingga kita dapat menggunakannya dalam cara yang sama dibagian kode selanjutnya.

\section{VGG-16}
\begin{figure}[!htp]
	\includegraphics[width=0.75\textwidth]{figures/vgg.jpeg}
	\caption{gambar VGG-16}
	\label{labelgambar1}
\end{figure}

Gambar diatas adalah arsitektur dari VGG16 (16 Layer). Yang akan kita gunakan adalah Feature Extraction Layer saja, tentu saja dengan weights yang dapat kita download. Weights nya berupa file .h5 seperti yang sudah kita gunakan sebelumnya.

FC layer pada VGG16 terdiri dari 4096–4096–4096 neuron pada hidden layer dan 1000 neuron pada output layer karena ImageNet mempunyai 1000 classs. Sedangkan dataset kita hanya mempunyai 2 class (Male/Female), sehingga kita harus membuat FC layer versi kita sendiri.

Kita akan menggunakan FC Layer yaitu 32 neuron pada hidden layer dan 1 neuron pada output dengan sigmoid activation
( pada gambar \ref{labelgambar1} ).

\textbf{VGG-16 Dependiencies and variable} 

namun pada hal ini kita membutuhkan package applications untuk dapat menggunakan VGG16.

gambar dibawah adalah salah satu contoh source code pada package applications dari VGG-16 Dependiencies and variable ( pada gambar \ref{labelgambar2} ).
\begin{figure}[!htp]
	\includegraphics[width=0.75\textwidth]{figures/vgg1.jpeg}
	\caption{gambar VGG-16 Dependiencies and variable}
	\label{labelgambar2}
\end{figure}

\textbf{VGG-16 Model and Data Augmentation}

gambar dibawah adalah salah satu contoh source code pada package applications dari VGG-16 Model and Data Augmentation
( pada gambar \ref{labelgambar3} ).
\begin{figure}[!htp]
	\includegraphics[width=0.75\textwidth]{figures/vgg2.JPG}
	\caption{gambar VGG-16 Model and Data Augmentation}
	\label{labelgambar3}
\end{figure}

Dengan menggunakan package applications kita bisa langsung menggunakan VGG-16 tanpa harus menyusunnya layer demi layer dan mendownload weights nya.

Argument include top sama dengan False diatas menandakan jika kita tidak menggunakan FC Layer dari VGG-16. Sehingga jika kita melakukan “predict” untuk model ini maka yang akan terjadi adalah dataset akan mengalir pada feature extraction layer dari VGG-16. 

Hasilnya adalah feature map yang bisa kita simpan pada file train features.npy dan val features.npy yang nantinya bisa kita flatten dan kita gunakan untuk melakukan training pada FC Layer versi kita sendiri.

\section{Convolutional Neural Network}
Convolutional Neural Network (CNN) adalah salah satu jenis neural network yang biasa digunakan pada data image. CNN bisa digunakan untuk mendeteksi dan mengenali object pada sebuah image.

Secara garis besar CNN tidak jauh beda dengan neural network biasanya. CNN terdiri dari neuron yang memiliki weight, biasa dan activation function seperti yang sudah kita pelajari pada part sebelumnya. Lalu apa yang membedakan? Arsitektur dari CNN dibagi menjadi 2 bagian besar, Feature Extraction Layer dan Fully-Connected Layer (MLP) 

\section{Feature Extraction Layer}
Saya gunakan istilah ini karena proses yang terjadi pada bagian ini adalah melakukan “encoding” dari sebuah image menjadi features yang berupa angka-angka yang merepresentasikan image tersebut (Feature Extraction).

Feature extraction layer terdiri dari dua bagian. Convolutional Layer dan Pooling Layer. Namun kadang ada beberapa riset/paper yang tidak menggunakan pooling(pada gambar \ref{labelgambar1} ).
\begin{figure}[!htp]
	\includegraphics[width=0.75\textwidth]{figures/FeatureExtractionLayer.PNG}
	\caption{Contoh FEL}
	\label{labelgambar1}
\end{figure}

\section{Convolutional Layer}
 Gambar \ref{labelgambar2} adalah RGB (Red, Green, Blue) image berukuran 32x32 pixels yang sebenarnya adalah multidimensional array dengan ukuran 32x32x3 (3 adalah jumlah channel).
Convolutional layer terdiri dari neuron yang tersusun sedemikian rupa sehingga membentuk sebuah filter dengan panjang dan tinggi (pixels). Sebagai contoh, layer pertama pada feature extraction layer biasanya adalah conv. layer dengan ukuran 5x5x3. Panjang 5 pixels, tinggi 5 pixels dan tebal/jumlah 3 buah sesuai dengan channel dari image tersebut.
Ketiga filter ini akan digeser keseluruh bagian dari gambar. Setiap pergeseran akan dilakukan operasi “dot” antara input dan nilai dari filter tersebut sehingga menghasilkan sebuah output atau biasa disebut sebagai activation map atau feature map

\begin{figure}[!htp]
	\includegraphics[width=0.75\textwidth]{figures/ConvolutionalLayer.PNG}
	\caption{Contoh CL}
	\label{labelgambar2}
\end{figure}



\section{Training with TensorBoard Visualization}
Kita akan menggunakan TensorBoard untuk melakukan visualisasi pada saat training. Seluruh training loss/accuracy dan validation loss/accuracy akan disimpan dan kita bisa melihat grafiknya.

Untuk menggunakan TensorBoard kita bisa gunakan command sebagai berikut :
\lstinputlisting[caption=Contoh TBV,label={lst:gambar3}]{src/tensorboard.py}

\begin{figure}[!htp]
	\includegraphics[width=0.75\textwidth]{figures/TensorBoardVisualization.PNG}
	\caption{Contoh TBV}
	\label{labelgambar3}
\end{figure}

\section{Comparing Two Model}
Dengan menggunakan TensorBoard, kita juga bisa membandingkan performa kedua model yang telah kita train.
\begin{figure}[!htp]
	\includegraphics[width=0.75\textwidth]{figures/ComparingTwoModel.PNG}
	\caption{Contoh CTM}
	\label{labelgambar4}
\end{figure}

Grafik warna biru diatas adalah grafik dari model kedua yang menggunakan conv. layer yang lebih banyak. Bisa dilihat disitu kalau performa dari model ini jelas lebih bagus daripada model pertama.

Training dan Validation Loss yang didapatkan adalah 0.1521 dan 0.2571, sedangkan Training dan Validation Accuracy sebesar 94.46 persen dan 91.28 persen.

Sebenarnya kedua model ini masih bisa dioptimasi lagi, bisa dicoba pake learning rate yang lebih tinggi misalnya 0.001, tapi epoch lebih kecil lagi atau setting jumlah neuron pada FC Layer dan masih banyak lagi untuk improve performa dari model kita.




\section{Transfer Learning}
Transfer learning adalah suatu teknik atau metode yang memanfaatkan model yang sudah dilatih terhadap suatu dataset untuk menyelesaikan permasalahan lain yang serupa dengan cara menggunakannya sebagai starting point, memodifikasi dan mengupdate parameternya sehingga sesuai dengan dataset yang baru.

Kita akan gunakan model VGG-16 yang sudah dilatih pada data ImageNet dengan cara membuat arsitektur yang identik dengan VGG-16 tetapi tanpa fully-connected layer dan mendownload weights nya. Dengan menyediakan beberapa model ImageNet yang populer untuk bisa kita gunakan.

Seluruh weight VGG-16 telah dilatih menggunakan dataset ImageNet dan sudah dapat mengenali warna, tekstur, dll. Sehingga kita bisa manfaatkan ini untuk meng-extract feature dari semua foto pada dataset kita.

\subsection{Transfer Learning Result}

\begin{figure}[!htp]
	\includegraphics[width=0.75\textwidth]{figures/Transfer.PNG}
	\caption{Transfer learning}
	\label{Transfer Learning}
\end{figure}

Setelah 50 epoch training-testing, kita mendapatkan loss dan accuracy sebesar 0.2985 crossentropy loss dan 90.44 persen accuracy ( pada gambar \ref{Transfer Learning} ) .

\begin{figure}[!htp]
	\includegraphics[width=0.75\textwidth]{figures/Grafik.PNG}
	\caption{Grafik Learning}
	\label{Grafik}
\end{figure}

Namun jika dilihat dari grafiknya, masih terjadi overfitting. Kita bisa tangani ini dengan cara menggunakan FC Layer yang lebih sederhana, menggunakan Dropout, melakukan augmentasi yang lebih agresif lagi atau menambah jumlah data ( pada gambar \ref{Grafik} ) .

\subsection{ImageNet}
ImageNet adalah sebuah dataset yang terdiri dari 1.200.000 gambar untuk training dan 100.000 untuk testing. Dataset ini terdiri dari 1000 classes jadi untuk setiap class ada 1.200 gambar.

Sebenarnya ImageNet challenge ini sudah dimulai sejak 2010, saya kurang paham algoritma dan model apa yang digunakan pada rentang 2010–2011. Namun hasil yang paling standout adalah AlexNet pada 2012. AlexNet adalah model pertama yang menggunakan Convolutional Neural Network (CNN). 

Seiring dengan perkembangan teknologi tiap tahun, jumlah layer yang digunakan juga mengalami kenaikan yang hasilnya bisa dibilang setara dengan tingkat akurasi yang dihasilkan.

\subsection{Data Augmentation}
\begin{figure}[!htp]
	\includegraphics[width=0.75\textwidth]{figures/Augmentation.PNG}
	\caption{Data Augmentation}
	\label{Augmentation}
\end{figure}

Seperti yang sudah kita ketahui, untuk mendapatkan performa yang optimal, Deep Learning membutuhkan data yang lebih banyak dibandingkan dengan algoritma ML yang lain.

Dari dataset yang telah kita kumpulkan hanya terdapat 400 foto pria dan 400 foto wanita. Jumlah data tersebut masih kurang mencukupi untuk mendapatkan performa yang optimal.

Untuk itu kita perlu meng-augmentasi data tersebut. Data Augmentation adalah sebuah teknik memanipulasi sebuah data tanpa kehilangan inti atau esensi dari data tersebut. Untuk data berupa Image, kita bisa lakukan rotate, flip, crop, dll ( Pada gambar \ref {Augmentation} ).

\begin{figure}[!htp]
	\includegraphics[width=0.75\textwidth]{figures/Contoh.PNG}
	\caption{Source Code Augmentation}
	\label{Source Code Augmentation}
\end{figure}

Pada percobaan kita kali ini, kita akan melakukan shear, zoom dan flip sedangkan parameter rescale yang kita gunakan adalah membagi nilai RGB dari 0–255 dengan 255, sehingga kita mendapatkan nilai RGB pada rentang 0–1. Untuk data testing kita hanya melakukan rescale saja.

Method flow from directory dari ImageDataGenerator kita gunakan untuk mengubah data yang berupa “raw image” menjadi sebuah dataset yang akan kita gunakan untuk training dan testing, tentu saja dataset yang telah kita augmentasi tadi  ( Pada gambar \ref{Source Code Augmentation} ).

\section{Deeper Network}
Kita bisa gunakan arsitektur yang lebih \textit{deep} dengan menambahkan conv. layer. Tapi yang patut diperhatikan adalah semakin deep arsitektur yang kita gunakan semakin lama proses training karena semakin banyak parameter yang harus diupdate. Arsitektur yang seperti ini juga rawan terjadi overfitting.

Model kedua yang akan kita coba menggunakan ukuran filter yang sama yaitu 5x5 dan 3x3, namun kita gunakan stride yang lebih kecil dan kita melakukan dua kali downsampling.

\begin{figure}[!htp]
	\includegraphics[width=0.75\textwidth]{figures/DeeperNetwork.PNG}
	\caption{Contoh DN}
	\label{labelgambar5}
\end{figure}


\section{Padding}
Padding atau Zero Padding adalah parameter yang menentukan jumlah pixels (berisi nilai 0) yang akan ditambahkan di setiap sisi dari input. Hal ini digunakan dengan tujuan untuk memanipulasi dimensi output dari conv. layer (Feature Map).

Tujuan dari penggunaan padding adalah :
\begin{enumerate}
\item Dimensi output dari convolutional layer selalu lebih kecil dari inputnya. Output ini akan digunakan kembali sebagai input dari convolutional layer selanjutnya, sehingga makin banyak informasi yang terbuang. Dengan menggunakan padding, kita dapat mengatur dimensi output agar tetap sama seperti dimensi input atau setidaknya tidak berkurang secara drastis.

\item Meningkatkan performa dari model karena convolutional filter akan fokus pada informasi yang sebenarnya yaitu yang berada diantara zero padding tersebut, Sehingga kita bisa menggunakan convolutional layer yang lebih dalam sehingga lebih banyak features yang berhasil di extract.
\end{enumerate}

\section{Stride}
Stride adalah parameter yang menentukan berapa jumlah pergeseran filter. Jika nilai stride adalah 1, maka conv. filter akan bergeser sebanyak 1 pixels secara horizontal lalu vertical.

Semakin kecil stride maka akan semakin detail informasi yang kita dapatkan dari sebuah input, namun membutuhkan komputasi yang lebih jika dibandingkan dengan stride yang besar. Namun perlu diperhatikan bahwa dengan menggunakan stride yang kecil kita tidak selalu akan mendapatkan performa yang bagus.


\section{KorNet}
Arsitektur sederhana kita ini terdiri dari 87.969 buah parameter yang akan diupdate pada saat training. Pada feature extraction layer terdapat 4 Convolution Layer, ZeroPadding Layer dan MaxPooling Layer.

Pada fully-connected layer terdapat 2 buah layer dengan jumlah neuron masing-masing sebanyak 32 dan 1. Perlu diingat bahwa layer terakhir adalah output layer. 1 buah layer disini karena kita akan melakukan binary classification, 0 untuk pria dan 1 untuk wanita. Sehingga activation function yang harus kita gunakan pada output layer adalah sigmoid dengan loss function binary crossentropy. Kita juga bisa menggunakan 2 neuron pada output layer, menggunakan activation function softmax dan loss function categorical crossentropy seperti pada Part-7.

\section{ResNet}
Model ResNet merupakan model yang menggunakan deep residual learning framework. Dengan menggunakan framework ini, setiap layer network memiliki referensi ke layer network sebelumnya; hal ini menjadikan proses optimasi menjadi lebih mudah daripada layer network-layer network yang tidak memiliki keterhubungan. Karena proses optimasi yang lebih mudah, neural network yang dibentuk
dapat memiliki jumlah layer yang banyak sampai dengan 34 layer dan akibatnya, akurasi meningkat dari neural network yang tidak menggunakan residual network.


\section{Pooling Layer}
Pooling layer biasanya berada setelah convolutional layer. Pada prinsipnya pooling layer terdiri dari sebuah filter dengan ukuran dan stride tertentu yang akan bergeser pada seluruh area feature map.

Pooling yang biasa digunakan adalah Max Pooling dan Average Pooling. Sebagai contoh jika kita menggunakan Max Pooling 2x2 dengan stride 2, maka pada setiap pergeseran filter, nilai maximum pada area 2x2 pixel tersebut yang akan dipilih, sedangkan Average Pooling akan memilih nilai rata-ratanya.

\begin{figure}[!htp]
	\includegraphics[width=0.75\textwidth]{figures/PoolingLayer.PNG}
	\caption{Contoh PL}
	\label{labelgambar6}
\end{figure}


Keuntungan dari ResNets adalah:

\begin{enumerate}
\item kinerja tidak menurun dengan jaringan yang sangat dalam
\item lebih murah untuk dihitung
\item kemampuan untuk melatih jaringan yang sangat dalam
\end{enumerate}

ResNet berfungsi karena:

\begin{enumerate}
\item mengidentifikasi fungsi mudah untuk blok residual untuk dipelajari
\item menggunakan koneksi-loncatan membantu gradien untuk kembali-menyebar dan dengan demikian membantu Anda untuk melatih jaringan yang lebih dalam
\end{enumerate}


\section{Fully Connected Layer} 
Feature map yang dihasilkan dari feature extraction layer masih berbentuk multidimensional array, sehingga kita harus melakukan flatten atau reshape feature map menjadi sebuah vector agar bisa kita gunakan sebagai input dari fully connected layer.

Fully Connected Layer yang dimaksud disini adalah MLP yang sudah pernah kita pelajari sama-sama pada bagian ke-4 dan bagian ke-5. Fully Connected Layer memiliki beberapa hidden layer, activation function, output layer dan loss function.

\section{The Problem}
Data MNIST diatas terdiri dari nilai 0–255 untuk setiap pixel yang ada. Kita bisa saja menggunakan MLP untuk melakukan klasifikasi untuk semua digit dengan hasil yang cukup baik karena sebagian besar data pada MNIST, object yang akan dikenali berada ditengah-tengah gambar.

Lalu bagaima jika object yang akan dikenali tidak berada ditengah-tengah gambar? Disinilah kelemahan dari MLP. Angka 6 yang berada ditengah-tengah gambar akan berhasil dikenali, tetapi angka 6 yang berada dipojok kiri mungkin tidak akan dikenali.

Kita bisa menggunakan data yang sangat banyak dengan tiap digit berada pada lokasi yang berbeda, namun ini bukan cara yang efisien untuk mengatasi permasalahan tersebut.

\section{Inception}
Motivasi dari jaringan awal adalah, daripada mengharuskan kita untuk memilih ukuran filter secara manual, biarkan jaringan memutuskan apa yang terbaik untuk dimasukkan ke dalam sebuah layer. Kami memberikan pilihan dan semoga akan mengambil yang terbaik untuk digunakan di lapisan itu ( pada gambar \ref{Inception} ) .
\begin{figure}[!htp]
	\includegraphics[width=0.75\textwidth]{figures/inception.PNG}
	\caption{gambar Inception}
	\label{Inception}
\end{figure}

\section{Data Pre-processing}
Pertama kita parse page tersebut dan convert HTML table menjadi CSV. Kita memiliki 115 buah data. Nanti ada 16 hero yang akan kita ambil sebagai validation dan sisanya kita gunakan sebagai training. Untuk validation data, kita ambil beberapa hero yang memiliki stats yang aneh seperti Jakiro, Winter Wyvern (Strength tinggi tapi termasuk INT hero), Phoenix, IO (Strength rendah tapi termasuk STR hero), Bloodseeker, Undying, dan lain lain.

Stats yang menurut saya tidak relevan akan kita buang, seperti Day Vision, Night Vision, Collision Size, Legs. Sehingga kita punya 22 features yang akan kita gunakan untuk melakukan klasifikasi. Type hero akan kita gunakan sebagai target yang memiliki nilai 0 untuk STR, 1 untuk AGI dan 2 untuk INT.

\section{Training a Neural Network}
Pada Supervised Learning menggunakan Neural Network, pada umumnya Learning terdiri dari 2 tahap, yaitu training dan evaluation. Namun kadang terdapat tahap tambahan yaitu testing, namun sifatnya tidak wajib.

Pada tahap training setiap weight dan bias pada tiap neuron akan diupdate terus menerus hingga output yang dihasilkan sesuai dengan harapan. Pada tiap iterasi akan dilakukan proses evaluation yang biasanya digunakan untuk menentukan kapan harus menghentikan proses training (stopping point).


\section{Artificial Neural Network}
Neural network adalah model yang terinspirasi oleh bagaimana neuron dalam otak manusia bekerja. Tiap neuron pada otak manusia saling berhubungan dan informasi mengalir dari setiap neuron tersebut. Gambar di bawah adalah ilustrasi neuron dengan model matematisnya. Tiap neuron menerima input dan melakukan operasi dot dengan sebuah weight, menjumlahkannya dan menambahkan bias. Hasil dari operasi ini akan dijadikan parameter dari activation function yang akan dijadikan output dari neuron tersebut ( pada gambar \ref{Artificial} ) .

\begin{figure}[!htp]
	\includegraphics[width=0.75\textwidth]{figures/ArtificialNeuralNetwork.PNG}
	\caption{gambar ANN }
	\label{Artificial}
\end{figure}

